{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-TEST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOSCCEavck76",
        "outputId": "6cd50338-1268-4ce0-bf17-0f96bad944e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "! pip install hiddenlayer graphviz torchviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hiddenlayer in /usr/local/lib/python3.6/dist-packages (0.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.18.5)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3520 sha256=ca7ad615a188fcf4865ec3d8f0bdce1c431a43f322315ecd05c99571f98c5fac\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkLX9oQrCuaG"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as Data\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import timeit\n",
        "import unittest\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(0)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mwpwfg9C0Cf"
      },
      "source": [
        "# check availability of GPU and set the device accordingly\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# define a transforms for preparing the dataset\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(), # convert the image to a pytorch tensor\n",
        "        transforms.Normalize((0.1307,), (0.3081,)) # normalise the images with mean and std of the dataset\n",
        "        ])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpaMZ02RC3tt"
      },
      "source": [
        "# Load the MNIST training, test datasets using `torchvision.datasets.MNIST` using the transform defined above\n",
        "\n",
        "train_dataset = datasets.MNIST('./data',train=True,transform=transform,download=True)\n",
        "test_dataset =  datasets.MNIST('./data',train=False,transform=transform,download=True)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSc46HzEC5Zr"
      },
      "source": [
        "# create dataloaders for training and test datasets\n",
        "# use a batch size of 32 and set shuffle=True for the training set\n",
        "\n",
        "train_dataloader = Data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = Data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMfiMDj_C7ii"
      },
      "source": [
        "# My Net\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # define a conv layer with output channels as 16, kernel size of 3 and stride of 1\n",
        "        self.conv11 = nn.Conv2d(1, 16, 3, 1) # Input = 1x28x28  Output = 16x26x26\n",
        "        self.conv12 = nn.Conv2d(1, 16, 5, 1) # Input = 1x28x28  Output = 16x24x24\n",
        "        self.conv13 = nn.Conv2d(1, 16, 7, 1) # Input = 1x28x28  Output = 16x22x22\n",
        "        self.conv14 = nn.Conv2d(1, 16, 9, 1) # Input = 1x28x28  Output = 16x20x20\n",
        "\n",
        "        # define a conv layer with output channels as 32, kernel size of 3 and stride of 1\n",
        "        self.conv21 = nn.Conv2d(16, 32, 3, 1) # Input = 16x26x26 Output = 32x24x24\n",
        "        self.conv22 = nn.Conv2d(16, 32, 5, 1) # Input = 16x24x24 Output = 32x20x20\n",
        "        self.conv23 = nn.Conv2d(16, 32, 7, 1) # Input = 16x22x22 Output = 32x16x16\n",
        "        self.conv24 = nn.Conv2d(16, 32, 9, 1) # Input = 16x20x20  Output = 32x12x12\n",
        "\n",
        "        # define a conv layer with output channels as 64, kernel size of 3 and stride of 1\n",
        "        self.conv31 = nn.Conv2d(32, 64, 3, 1) # Input = 32x24x24 Output = 64x22x22\n",
        "        self.conv32 = nn.Conv2d(32, 64, 5, 1) # Input = 32x20x20 Output = 64x16x16\n",
        "        self.conv33 = nn.Conv2d(32, 64, 7, 1) # Input = 32x16x16 Output = 64x10x10\n",
        "        self.conv34 = nn.Conv2d(32, 64, 9, 1) # Input = 32x12x12 Output = 64x4x4\n",
        "        \n",
        "\n",
        "        # define a max pooling layer with kernel size 2\n",
        "        self.maxpool = nn.MaxPool2d(2) # Output = 64x11x11\n",
        "        #self.maxpool1 = nn.MaxPool2d(1)\n",
        "        # define dropout layer with a probability of 0.25\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        # define dropout layer with a probability of 0.5\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        # define a linear(dense) layer with 128 output features\n",
        "        self.fc11 = nn.Linear(64*11*11, 128)\n",
        "        self.fc12 = nn.Linear(64*8*8, 128)      # after maxpooling 2x2\n",
        "        self.fc13 = nn.Linear(64*5*5, 128)\n",
        "        self.fc14 = nn.Linear(64*4*4, 128)\n",
        "\n",
        "        # define a linear(dense) layer with output features corresponding to the number of classes in the dataset\n",
        "        self.fc21 = nn.Linear(128, 64)\n",
        "        self.fc22 = nn.Linear(128, 64)\n",
        "        self.fc23 = nn.Linear(128, 64)\n",
        "        self.fc24 = nn.Linear(128, 64)\n",
        "\n",
        "        self.fc33 = nn.Linear(64*4,10)\n",
        "        #self.fc33 = nn.Linear(64*3,10)\n",
        "        \n",
        "\n",
        "    def forward(self, inp):\n",
        "        # Use the layers defined above in a sequential way (folow the same as the layer definitions above) and \n",
        "        # write the forward pass, after each of conv1, conv2, conv3 and fc1 use a relu activation. \n",
        "        \n",
        "\n",
        "        x = F.relu(self.conv11(inp))\n",
        "        x = F.relu(self.conv21(x))\n",
        "        x = F.relu(self.maxpool(self.conv31(x)))\n",
        "        #print(x.shape)\n",
        "        #x = torch.flatten(x, 1)\n",
        "        x = x.view(-1,64*11*11)\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc11(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc21(x)\n",
        "\n",
        "        y = F.relu(self.conv12(inp))\n",
        "        y = F.relu(self.conv22(y))\n",
        "        y = F.relu(self.maxpool(self.conv32(y)))\n",
        "        #x = torch.flatten(x, 1)\n",
        "        y = y.view(-1,64*8*8)\n",
        "        y = self.dropout1(y)\n",
        "        y = F.relu(self.fc12(y))\n",
        "        y = self.dropout2(y)\n",
        "        y = self.fc22(y)\n",
        "\n",
        "        z = F.relu(self.conv13(inp))\n",
        "        z = F.relu(self.conv23(z))\n",
        "        z = F.relu(self.maxpool(self.conv33(z)))\n",
        "        #x = torch.flatten(x, 1)\n",
        "        z = z.view(-1,64*5*5)\n",
        "        z = self.dropout1(z)\n",
        "        z = F.relu(self.fc13(z))\n",
        "        z = self.dropout2(z)\n",
        "        z = self.fc23(z)\n",
        "\n",
        "        ze = F.relu(self.conv14(inp))\n",
        "        ze = F.relu(self.conv24(ze))\n",
        "        ze = F.relu(self.conv34(ze))\n",
        "        #x = torch.flatten(x, 1)\n",
        "        ze = ze.view(-1,64*4*4)\n",
        "        ze = self.dropout1(ze)\n",
        "        ze = F.relu(self.fc14(ze))\n",
        "        ze = self.dropout2(ze)\n",
        "        ze = self.fc24(ze)\n",
        "\n",
        "        out_f = torch.cat((x, y, z, ze), dim=1)\n",
        "        #out_f1 = torch.cat((out_f, ze), dim=1)\n",
        "        out = self.fc33(out_f)\n",
        "        \n",
        "        output = F.log_softmax(out, dim=1)\n",
        "        return output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6cKqdumF2hP",
        "outputId": "e12bf4ff-108c-4fcb-dee2-3b2a68af4967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.cat((torch.tensor([1,2]),torch.tensor([2,3]),torch.tensor([3,4]),torch.tensor([3,4])),dim=0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 2, 3, 3, 4, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km_vGjW5GCw2",
        "outputId": "9fcf1c4c-fa1d-4541-aee2-83f5965385f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.tensor(1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_8aY_rkdQa_"
      },
      "source": [
        "model = Net().to(device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKdVTXGParPn",
        "outputId": "6d26880b-be5d-4020-8bce-f716f53441f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "print(model.parameters)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.parameters of Net(\n",
            "  (conv11): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv12): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv13): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (conv14): Conv2d(1, 16, kernel_size=(9, 9), stride=(1, 1))\n",
            "  (conv21): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv22): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv23): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (conv24): Conv2d(16, 32, kernel_size=(9, 9), stride=(1, 1))\n",
            "  (conv31): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv32): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv33): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (conv34): Conv2d(32, 64, kernel_size=(9, 9), stride=(1, 1))\n",
            "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout1): Dropout(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc11): Linear(in_features=7744, out_features=128, bias=True)\n",
            "  (fc12): Linear(in_features=4096, out_features=128, bias=True)\n",
            "  (fc13): Linear(in_features=1600, out_features=128, bias=True)\n",
            "  (fc14): Linear(in_features=1024, out_features=128, bias=True)\n",
            "  (fc21): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc22): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc23): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc24): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc33): Linear(in_features=256, out_features=10, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2gKNeLpLvF0",
        "outputId": "da549c08-10eb-45f6-b598-ebff90d1109d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import unittest\n",
        "\n",
        "class TestImplementations(unittest.TestCase):\n",
        "    \n",
        "    # Dataloading tests\n",
        "    def test_dataset(self):\n",
        "        self.dataset_classes = ['0 - zero',\n",
        "                                '1 - one',\n",
        "                                '2 - two',\n",
        "                                '3 - three',\n",
        "                                '4 - four',\n",
        "                                '5 - five',\n",
        "                                '6 - six',\n",
        "                                '7 - seven',\n",
        "                                '8 - eight',\n",
        "                                '9 - nine']\n",
        "        self.assertTrue(train_dataset.classes == self.dataset_classes)\n",
        "        self.assertTrue(train_dataset.train == True)\n",
        "    \n",
        "    def test_dataloader(self):        \n",
        "        self.assertTrue(train_dataloader.batch_size == 32)\n",
        "        self.assertTrue(test_dataloader.batch_size == 32)      \n",
        "         \n",
        "    def test_total_parameters(self):\n",
        "        model = Net().to(device)\n",
        "        #self.assertTrue(sum(p.numel() for p in model.parameters()) == 1015946)\n",
        "\n",
        "suite = unittest.TestLoader().loadTestsFromModule(TestImplementations())\n",
        "unittest.TextTestRunner().run(suite)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F..\n",
            "======================================================================\n",
            "FAIL: test_dataloader (__main__.TestImplementations)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-10-80e7f3fdfcef>\", line 21, in test_dataloader\n",
            "    self.assertTrue(train_dataloader.batch_size == 32)\n",
            "AssertionError: False is not true\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.037s\n",
            "\n",
            "FAILED (failures=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=3 errors=0 failures=1>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkxM8CJsIP0x"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbjgB4h7C9jF"
      },
      "source": [
        "losses_1 = []\n",
        "losses_2 = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # send the image, target to the device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # flush out the gradients stored in optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # pass the image to the model and assign the output to variable named output\n",
        "        output = model(data)\n",
        "        # calculate the loss (use nll_loss in pytorch)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        # do a backward pass\n",
        "        loss.backward()\n",
        "        # update the weights\n",
        "        optimizer.step()\n",
        "      \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            losses_1.append(loss.item())\n",
        "            losses_2.append(100. * batch_idx / len(train_loader))\n",
        "        "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-F4lOp9DAVs"
      },
      "source": [
        "accuracy = []\n",
        "avg_loss = []\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "          \n",
        "            # send the image, target to the device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # pass the image to the model and assign the output to variable named output\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "          \n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    avg_loss.append(test_loss)\n",
        "    accuracy.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDi1oAglJVEn",
        "outputId": "53dc93cd-e6dc-46ee-a73a-07e9577dda7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "def adjust_learning_rate(optimizer, iter, each):\n",
        "    # sets the learning rate to the initial LR decayed by 0.1 every 'each' iterations\n",
        "    lr = 0.001 * (0.8 ** (iter // each))\n",
        "    state_dict = optimizer.state_dict()\n",
        "    for param_group in state_dict['param_groups']:\n",
        "        param_group['lr'] = lr\n",
        "    optimizer.load_state_dict(state_dict)\n",
        "    print(\"Learning rate = \",lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "## Define Adam Optimiser with a learning rate of 0.01\n",
        "optimizer =  torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "start = timeit.default_timer()\n",
        "for epoch in range(1,100):\n",
        "  adjust_learning_rate(optimizer, epoch, 1.616)\n",
        "  train(model, device, train_dataloader, optimizer, epoch)\n",
        "  test(model, device, test_dataloader)\n",
        "stop = timeit.default_timer()\n",
        "print('Total time taken: {} seconds'.format(int(stop - start)) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate =  0.001\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304556\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.186423\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.146253\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.205674\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.139127\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.043099\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.090732\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.033158\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.012802\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.076438\n",
            "\n",
            "Test set: Average loss: 0.0432, Accuracy: 9857/10000 (99%)\n",
            "\n",
            "Learning rate =  0.0008\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.048899\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.019148\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.068627\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.034134\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.017864\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.085047\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.072187\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.053785\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.088112\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.196154\n",
            "\n",
            "Test set: Average loss: 0.0402, Accuracy: 9867/10000 (99%)\n",
            "\n",
            "Learning rate =  0.0008\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.157668\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.008403\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.005561\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.008817\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.025136\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.002024\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.007856\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.008827\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.058997\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.009284\n",
            "\n",
            "Test set: Average loss: 0.0267, Accuracy: 9926/10000 (99%)\n",
            "\n",
            "Learning rate =  0.0006400000000000002\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.007983\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.096480\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.074094\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.000856\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.002542\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.000657\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.013731\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.003418\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.003577\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.002239\n",
            "\n",
            "Test set: Average loss: 0.0193, Accuracy: 9936/10000 (99%)\n",
            "\n",
            "Learning rate =  0.0005120000000000001\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.014809\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000900\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.002937\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.000096\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.105246\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.018756\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.003249\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000564\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.008341\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.001844\n",
            "\n",
            "Test set: Average loss: 0.0264, Accuracy: 9908/10000 (99%)\n",
            "\n",
            "Learning rate =  0.0005120000000000001\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.141196\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000410\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.004895\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.003050\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.015534\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.003692\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.001627\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.012860\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.009972\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.006106\n",
            "\n",
            "Test set: Average loss: 0.0198, Accuracy: 9930/10000 (99%)\n",
            "\n",
            "Learning rate =  0.0004096000000000001\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000169\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.005404\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.007810\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.000280\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.003485\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.001494\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.008619\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.000324\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.054573\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.004017\n",
            "\n",
            "Test set: Average loss: 0.0218, Accuracy: 9937/10000 (99%)\n",
            "\n",
            "Learning rate =  0.0004096000000000001\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000676\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.007478\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.001849\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.000623\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.002456\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.005703\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.001609\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.026566\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.001174\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.026548\n",
            "\n",
            "Test set: Average loss: 0.0195, Accuracy: 9941/10000 (99%)\n",
            "\n",
            "Learning rate =  0.0003276800000000001\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.001122\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000184\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.070053\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000217\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.002797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL_EcYPWJav3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses_1, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Losses');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx6-9hOS_DR6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses_2, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Losses');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15qTg0VU_59t"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(avg_loss, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Losses');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaFA_cdg_98O"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(accuracy, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Losses');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6rhco42ACf6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}